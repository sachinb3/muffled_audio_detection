import sounddevice as sd
import numpy as np
import tensorflow_hub as hub
import tensorflow as tf
import joblib
import time
import os
import librosa
import pandas as pd

os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

# Load model and classifier
classifier = joblib.load('muffled_audio_classifier_live_training.pkl')
yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')


# Constants
DURATION = 3  # seconds
SAMPLE_RATE = 16000 # YAMNET default
FRAME_COUNT = SAMPLE_RATE * DURATION
SILENCE_THRESHOLD = 0.002 # Guess

def classify_audio(audio):
    try:
        audio = np.array(audio, dtype=np.float32)

        # Trim or pad to 3s
        if len(audio) < FRAME_COUNT:
            audio = np.pad(audio, (0, FRAME_COUNT - len(audio)))
        elif len(audio) > FRAME_COUNT:
            audio = audio[:FRAME_COUNT]

        _, embeddings, _ = yamnet_model(audio)
        embedding = tf.reduce_mean(embeddings, axis=0).numpy()

        proba = classifier.predict_proba([embedding])[0]
        prediction = np.argmax(proba)
        confidence = proba[prediction]

        return prediction, confidence

    except Exception as e:
        print(f"‚ùå Error in classification: {e}")
        return None, None

def audio_callback(indata, frames, time_info, status):
    if status:
        print(f"Stream status: {status}")

    audio_data = indata[:, 0]
    rms = np.sqrt(np.mean(audio_data**2))

    if rms < SILENCE_THRESHOLD:
        print("NO AUDIO üö´")
        return

    prediction, confidence = classify_audio(audio_data)
    if prediction is not None:
        label = "CLEAR AUDIO ‚úÖ" if prediction == 0 else "MUFFLED AUDIO üîá"
        print(f"{label} (Confidence: {confidence:.2%})")

def listen_and_classify():
    print("üéôÔ∏è Listening to microphone (3s chunks)...")
    with sd.InputStream(callback=audio_callback, channels=1, samplerate=SAMPLE_RATE,
                        blocksize=FRAME_COUNT, dtype='float32'):
        while True:
            time.sleep(0.1)

def classify_audio_file_realtime_chunks(file_path, actual_log_file="actual_muffling_log.csv"):
   """
   Classify audio in real-time chunks and append classification results to the actual muffling log (starting at Column E).
   Args:
       file_path (str): Path to the audio file to classify.
       actual_log_file (str): Path to the actual muffling log generated by randomly_muffle().
   """
   print(f"üîç Classifying in {DURATION}-second chunks: {file_path}")
   waveform, sr = librosa.load(file_path, sr=SAMPLE_RATE)
   total_samples = len(waveform)
   step = int(SAMPLE_RATE * DURATION)  # Ensure step size is an integer
   current = 0

   # Load the actual muffling log
   try:
       actual_log = pd.read_csv(actual_log_file)
   except FileNotFoundError:
       print(f"‚ùå Actual muffling log file not found: {actual_log_file}")
       return

   # Prepare a DataFrame to log the classification results
   classification_log = []

   # Play audio during classification
   sd.play(waveform, samplerate=sr)

   while current + step <= total_samples:
       # Convert indices to integers to avoid slicing errors
       segment = waveform[int(current):int(current + step)]
       prediction, confidence = classify_audio(segment)
       timestamp = current / SAMPLE_RATE

       if prediction is not None:
           label = "CLEAR AUDIO ‚úÖ" if prediction == 0 else "MUFFLED AUDIO üîá"
           start_time = current / SAMPLE_RATE
           end_time = (current + step) / SAMPLE_RATE
           print(f"[{start_time:.2f}s ‚Üí {end_time:.2f}s] {label} (Confidence: {confidence:.2%})")

           # Append classification results to the log
           classification_log.append({
               "Chunk": len(classification_log),  # Ensure chunk indices match
               "Classification Result": label,  # Classification result
               "Confidence (%)": round(confidence * 100, 2)  # Confidence score
           })

       current += step
       time.sleep(DURATION)

   print("‚úÖ Finished.")
   sd.stop()

   # Save the classification log to a DataFrame
   if classification_log:
       classification_df = pd.DataFrame(classification_log)

       # Merge actual muffling log with classification results
       actual_log = actual_log.merge(
           classification_df,  # The classification results
           on="Chunk",  # Match by chunk index
           how="left"  # Ensure all chunks in actual log are retained
       )

       # Overwrite the existing actual_log_file with the updated data
       actual_log.to_csv(actual_log_file, index=False)
       print(f"‚úÖ Updated actual muffling log saved to {actual_log_file}")
   else:
       print("‚ùå No classification results were generated.")


def main():
    print("üîò Choose mode:\n1. Microphone (3s blocks)\n2. Classify audio file")
    choice = input("Enter 1 or 2: ").strip()
    if choice == "1":
        listen_and_classify()
    elif choice == "2":
        file_path = input("üìÇ Enter full path to audio file (.wav/.mp3): ").strip()
        if not os.path.exists(file_path):
            print("‚ùå File not found.")
            return
        classify_audio_file_realtime_chunks(file_path)
    else:
        print("‚ùå Invalid input.")

if __name__ == "__main__":
    main()
